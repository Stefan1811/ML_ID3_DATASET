{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema kMeans-Bodescu Stefan Rares-E1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "1. My dataset contains attributes with data from certain people, data that can determine if that person is prone to a heart attack.\n",
    "   \n",
    "   Dataset attributes:\n",
    "   * age\n",
    "   * sex\n",
    "   * chest pain type(cp)\n",
    "   * resting blood pressure(trestbps)\n",
    "   * serum cholestoral in mg/dl(chol)\n",
    "   * fasting blood sugar > 120 mg/dl(fbs)\n",
    "   * resting electrocardiographic results(restecg)\n",
    "   * maximum heart rate achieved(thalach)\n",
    "   * exercise induced angina(exang)\n",
    "   * oldpeak = ST depression induced by exercise relative to rest(oldpeak)\n",
    "   * the slope of the peak exercise ST segment(slope)\n",
    "   * number of major vessels (0-3) colored by flourosopy(ca)\n",
    "   * thal: 0 = normal; 1 = fixed defect; 2 = reversable defect(thal)\n",
    "\n",
    "   The target attribute of the data set is \"target\".\n",
    "   The purpose of the data set is to determine if, depending on the above attributes, a person is prone to a heart attack.\n",
    "   \n",
    "   The discrete attributes of the dataset:\n",
    "   * sex(0,1)\n",
    "   * cp(0,1,2,3)\n",
    "   * fbs(0,1)\n",
    "   * restecg(0,1,2)\n",
    "   * exang(0,1)\n",
    "   * slope(0,1,2)\n",
    "   * ca(0,1,2,3,4)\n",
    "   * thal(0,1,2,3)\n",
    "   * target(0,1)\n",
    "\n",
    "   The continuous attributes of the data set:\n",
    "   * age(29-77)\n",
    "   * trestbps(94-220)\n",
    "   * chol(126-564)\n",
    "   * thalach(71-202)\n",
    "   * oldpeak(0,6.2)\n",
    "\n",
    "\n",
    "2. My dataset doesn't contain NaN values.\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values:\n",
      " age          54.366337\n",
      "sex           0.683168\n",
      "cp            0.966997\n",
      "trestbps    131.623762\n",
      "chol        246.264026\n",
      "fbs           0.148515\n",
      "restecg       0.528053\n",
      "thalach     149.646865\n",
      "exang         0.326733\n",
      "oldpeak       1.039604\n",
      "slope         1.399340\n",
      "ca            0.729373\n",
      "thal          2.313531\n",
      "target        0.544554\n",
      "dtype: float64\n",
      "\n",
      "Variance values:\n",
      " age           82.484558\n",
      "sex            0.217166\n",
      "cp             1.065132\n",
      "trestbps     307.586453\n",
      "chol        2686.426748\n",
      "fbs            0.126877\n",
      "restecg        0.276528\n",
      "thalach      524.646406\n",
      "exang          0.220707\n",
      "oldpeak        1.348095\n",
      "slope          0.379735\n",
      "ca             1.045724\n",
      "thal           0.374883\n",
      "target         0.248836\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('https://raw.githubusercontent.com/Stefan1811/ML_ID3_DATASET/main/heart_attack.csv')\n",
    "train_data = train_data.dropna()\n",
    "\n",
    "mean_values = train_data.mean()\n",
    "variance_values = train_data.var()\n",
    "\n",
    "print(\"Mean values:\\n\", mean_values)\n",
    "print(\"\\nVariance values:\\n\", variance_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('https://raw.githubusercontent.com/Stefan1811/ML_ID3_DATASET/main/heart_attack.csv')\n",
    "train_data = train_data.dropna()\n",
    "\n",
    "mean_values = train_data.mean()\n",
    "variance_values = train_data.var()\n",
    "\n",
    "#print(\"Mean values:\\n\", mean_values)\n",
    "#print(\"\\nVariance values:\\n\", variance_values)\n",
    "\n",
    "target_attribute = 'target'\n",
    "discrete_attributes = ['sex','cp','fbs','restecg','exang','slope','ca','thal']\n",
    "continuous_attributes=['age','trestbps','chol','thalach','oldpeak']\n",
    "\n",
    "train_data = train_data.drop(target_attribute, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distances \n",
    "1. For the discrete attributes that aren't numerical, I can transform them in this way:\n",
    "   -boolean attributes can be transformed like this: true-1, false-0\n",
    "   -others attributes can be manually mapped, like this: sunny-0,cloudy-1, rainy-2\n",
    "\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Minkowski distance:\n",
      " 5.196152422706632\n"
     ]
    }
   ],
   "source": [
    "def distance_points(a,b,p):\n",
    "    distance=0\n",
    "    if len(a)!= len(b):\n",
    "        return -1\n",
    "    else:\n",
    "        for i in range(len(a)):\n",
    "            distance+=abs(a[i]-b[i])**p\n",
    "        return distance**(1/p)\n",
    "\n",
    "a=[1,2,3]\n",
    "b=[4,5,6]\n",
    "print(\" Minkowski distance:\\n\",distance_points(a,b,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random points:\n",
      " [[7.219987722668248, 9.385527090157503, 0.007787658410143283], [9.922115592912174, 6.1748150962771655, 6.116531604882809], [0.07066305219717406, 0.23062425041415757, 5.2477466025838915], [3.9986097171525548, 0.46665663213615427, 9.737555188414591], [2.3277134043030423, 0.906064345328208, 6.183860093330873]]\n"
     ]
    }
   ],
   "source": [
    "def generate_random_points(n,dimensions,left_range, right_range):\n",
    "    points=[]\n",
    "    for i in range(n):\n",
    "        point=[]\n",
    "        for j in range(dimensions):\n",
    "            point.append(np.random.uniform(left_range,right_range))\n",
    "        points.append(point)\n",
    "    return points\n",
    "\n",
    "print(\"Random points:\\n\",generate_random_points(5,3,0,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance to data frame:\n",
      " [0.         4.35889894 2.44948974]\n"
     ]
    }
   ],
   "source": [
    "def distance_to_df(train_data,x,p):\n",
    "    if len(x) != len(train_data.columns):\n",
    "        raise ValueError(\"Point X must have the same number of dimensions as DataFrame df\")\n",
    "\n",
    "    distances = np.linalg.norm(df.values - np.array(x), ord=p, axis=1)\n",
    "    return distances\n",
    "\n",
    "data = {'Feature1': [1, 2, 3],\n",
    "        'Feature2': [2, 5, 1],\n",
    "        'Feature3': [3, 6, 2]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "point_X = [1, 2, 3]\n",
    "\n",
    "print(\"Distance to data frame:\\n\",distance_to_df(df,point_X,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kMeans\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance to centroids:\n",
      " [array([0.        , 4.35889894, 2.44948974]), array([5.19615242, 2.        , 5.74456265]), array([10.39230485,  6.55743852, 10.67707825])]\n"
     ]
    }
   ],
   "source": [
    "def distance_to_centroids(train_data,centroids_list,p):\n",
    "    distances=[]\n",
    "    for centroid in centroids_list:\n",
    "           distances.append(distance_to_df(train_data,centroid,p))\n",
    "    return distances\n",
    "\n",
    "centroids_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "print(\"Distance to centroids:\\n\",distance_to_centroids(df,centroids_list,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest centroid:\n",
      " [0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "def closest_centroid(distances):\n",
    "    closest_centroid=[]\n",
    "    for i in range(len(distances[0])):\n",
    "        closest_centroid.append(np.argmin([distances[j][i] for j in range(len(distances))]))\n",
    "    return closest_centroid\n",
    "\n",
    "distances=distance_to_centroids(df,centroids_list,2)\n",
    "print(\"Closest centroid:\\n\",closest_centroid(distances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters:\n",
      " {0: [0, 2], 1: [1], 2: []}\n"
     ]
    }
   ],
   "source": [
    "def get_clusters(closest_centroid_list):\n",
    "    clusters = {}\n",
    "    \n",
    "    for i, centroid_index in enumerate(closest_centroid_list):\n",
    "        if centroid_index not in clusters:\n",
    "            clusters[centroid_index] = []\n",
    "        clusters[centroid_index].append(i)\n",
    "    \n",
    "    for i in range(len(closest_centroid_list)):\n",
    "        if i not in clusters:\n",
    "            clusters[i] = []\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "\n",
    "closest_centroid_list=closest_centroid(distances)\n",
    "print(\"Clusters:\\n\",get_clusters(closest_centroid_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New centroids:\n",
      " [array([2. , 1.5, 2.5]), [4, 5, 6], [7, 8, 9]]\n"
     ]
    }
   ],
   "source": [
    "def update_centroids(train_data, centroids_list, clusters):\n",
    "    new_centroids = []\n",
    "    for centroid_index in range(len(clusters)):\n",
    "        point_indices = clusters.get(centroid_index, [])\n",
    "        if not point_indices:\n",
    "            new_centroids.append(centroids_list[centroid_index])\n",
    "        elif len(point_indices) == 1:\n",
    "            new_centroids.append(centroids_list[centroid_index])\n",
    "        else:\n",
    "            cluster_points = train_data.iloc[point_indices]\n",
    "            new_centroid = cluster_points.mean().values\n",
    "            new_centroids.append(new_centroid)\n",
    "    return new_centroids\n",
    "\n",
    "\n",
    "clusters=get_clusters(closest_centroid_list)\n",
    "print(\"New centroids:\\n\",update_centroids(df,centroids_list,clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans++:\n",
      " [array([3, 1, 2], dtype=int64), array([2, 5, 6], dtype=int64), array([1, 2, 3], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "def kmeans_plusplus_init(train_data, n_clusters, random_seed=None):\n",
    "    np.random.seed(random_seed)\n",
    "    centroids = [train_data.iloc[np.random.choice(len(df))].values]\n",
    "    for _ in range(1, n_clusters):\n",
    "        distances = np.array([min(np.linalg.norm(point - centroid) ** 2 for centroid in centroids) for point in train_data.values])\n",
    "        probabilities = distances / distances.sum()\n",
    "        new_centroid = train_data.iloc[np.random.choice(len(df), p=probabilities)].values\n",
    "        centroids.append(new_centroid)\n",
    "    return centroids\n",
    "\n",
    "print(\"Kmeans++:\\n\",kmeans_plusplus_init(df,3,random_seed=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans:\n",
      " {'clusters': {1: [0, 1, 2], 0: [], 2: []}, 'centroids': [[7.796910002727692, 5.96850157946487, 4.458327528535912], array([2.        , 2.66666667, 3.66666667]), [1.4286681792194078, 6.508884729488528, 0.5641157902710026]]}\n"
     ]
    }
   ],
   "source": [
    "def kmeans(train_data, n_clusters, max_iter=100, init_type='random', random_seed=None):\n",
    "    if init_type == 'random':\n",
    "        centroids = generate_random_points(n_clusters, len(train_data.columns), 0, 10)\n",
    "    elif init_type == 'kmeans++':\n",
    "        centroids = kmeans_plusplus_init(train_data, n_clusters, random_seed)\n",
    "    else:\n",
    "        raise ValueError('Unsupported init_type: %s' % init_type)\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        distances = distance_to_centroids(train_data, centroids, 2)\n",
    "        closest_centroids = closest_centroid(distances)\n",
    "        clusters = get_clusters(closest_centroids)\n",
    "        new_centroids = update_centroids(train_data, centroids, clusters)\n",
    "        \n",
    "        if np.allclose(centroids, new_centroids):\n",
    "            break\n",
    "        \n",
    "        centroids = new_centroids\n",
    "    \n",
    "    result = {'clusters': clusters, 'centroids': centroids}\n",
    "    return result\n",
    "\n",
    "print(\"Kmeans:\\n\",kmeans(df,3,random_seed=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J score:\n",
      " 10.0\n"
     ]
    }
   ],
   "source": [
    "def calculate_J_score(df, membership, centroids):\n",
    "    J_score = 0\n",
    "    for i, centroid in enumerate(centroids):\n",
    "        cluster_points = df.iloc[membership[i]]\n",
    "        J_score += np.linalg.norm(cluster_points - centroid) ** 2\n",
    "    return J_score\n",
    "print(\"J score:\\n\",calculate_J_score(df,clusters,centroids_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
